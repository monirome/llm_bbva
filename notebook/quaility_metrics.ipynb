{
 "cells": [
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../afasia_llm\"))\n",
    "\n",
    "import itertools, random, time, warnings, re, json, os, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from afasia_llm.generate import (\n",
    "    generate_exercises_local,\n",
    "    generate_exercises_llm,\n",
    "    is_valid_exercise,\n",
    "    EXERCISE_BANK,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.style.use(\"default\")\n",
    "sns.set_palette(\"husl\")"
   ],
   "id": "26a5beb3b163e7cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Aplanar el banco de ejercicios\n",
    "BANK_SET = {\n",
    "    ex for sev_dict in EXERCISE_BANK.values()\n",
    "    for lst in sev_dict.values() for ex in lst\n",
    "}\n",
    "\n",
    "\n",
    "def novelty_ratio(generated: list[str]) -> float:\n",
    "    \"\"\"% de ejercicios que NO están en el banco clínico.\"\"\"\n",
    "    if not generated:\n",
    "        return 0.0\n",
    "    return sum(e not in BANK_SET for e in generated) / len(generated)"
   ],
   "id": "f5305c170eb23dce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T20:29:16.990354Z",
     "start_time": "2025-06-29T20:29:16.986298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "random.seed(42)\n",
    "\n",
    "APHASIA_TYPES = [\"Broca\", \"Wernicke\", \"TransMotor\"]\n",
    "SEVERITIES = [\"Severe\", \"Moderate\", \"Mild\"]\n",
    "\n",
    "patients = [\n",
    "    {\"id\": i, \"type\": t, \"sev\": s}\n",
    "    for i, (t, s) in enumerate(\n",
    "        random.choices(list(itertools.product(APHASIA_TYPES, SEVERITIES)), k=30)\n",
    "    )\n",
    "]\n",
    "\n",
    "df_patients = pd.DataFrame(patients)"
   ],
   "id": "de07c345c9be157a",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Usando dispositivo:\", DEVICE)\n",
    "\n",
    "LLM_NAME = \"google/flan-t5-base\"\n",
    "LLM_MODEL = AutoModelForSeq2SeqLM.from_pretrained(LLM_NAME).to(DEVICE)\n",
    "LLM_TOKENIZER = AutoTokenizer.from_pretrained(LLM_NAME)"
   ],
   "id": "449c21e79da63c1d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T21:10:18.386920Z",
     "start_time": "2025-06-29T20:29:16.991575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rows = []\n",
    "\n",
    "for p in patients:\n",
    "    pid, typ, sev = p[\"id\"], p[\"type\"], p[\"sev\"]\n",
    "\n",
    "    # LLM\n",
    "    t0 = time.time()\n",
    "    ex_llm = generate_exercises_llm(sev, typ, \"daily activities\", n=5, max_tries=3)\n",
    "    t_llm = time.time() - t0\n",
    "\n",
    "    # Plantilla\n",
    "    t0 = time.time()\n",
    "    ex_loc = generate_exercises_local(sev, typ, \"daily activities\", n=5)\n",
    "    t_loc = time.time() - t0\n",
    "\n",
    "    rows.append(dict(\n",
    "        id=pid,\n",
    "        type=typ,\n",
    "        sev=sev,\n",
    "        llm_valid=sum(map(is_valid_exercise, ex_llm)),\n",
    "        loc_valid=sum(map(is_valid_exercise, ex_loc)),\n",
    "        llm_novel=novelty_ratio(ex_llm),\n",
    "        loc_novel=novelty_ratio(ex_loc),\n",
    "        llm_len=np.mean([len(e.split()) for e in ex_llm]),\n",
    "        loc_len=np.mean([len(e.split()) for e in ex_loc]),\n",
    "        t_llm=t_llm,\n",
    "        t_loc=t_loc,\n",
    "    ))\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(f\"Analizados {len(df)} pacientes sinteticos\")"
   ],
   "id": "42c332dad724d8f4",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 8\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# LLM\u001B[39;00m\n\u001B[1;32m      7\u001B[0m t0 \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m----> 8\u001B[0m ex_llm \u001B[38;5;241m=\u001B[39m \u001B[43mgenerate_exercises_llm\u001B[49m\u001B[43m(\u001B[49m\u001B[43msev\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtyp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdaily activities\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_tries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m t_llm \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m t0\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# Plantilla\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/Barbara_things/afasia_llm_project/afasia_llm/generate.py:119\u001B[0m, in \u001B[0;36mgenerate_exercises_llm\u001B[0;34m(severity, aphasia_type, topic, n, max_tries)\u001B[0m\n\u001B[1;32m    116\u001B[0m     collected \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m [g \u001B[38;5;28;01mfor\u001B[39;00m g \u001B[38;5;129;01min\u001B[39;00m gen \u001B[38;5;28;01mif\u001B[39;00m g \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m collected]\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(collected) \u001B[38;5;241m<\u001B[39m n:  \u001B[38;5;66;03m# fallback seguro\u001B[39;00m\n\u001B[0;32m--> 119\u001B[0m     collected \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mgenerate_exercises_local\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    120\u001B[0m \u001B[43m        \u001B[49m\u001B[43mseverity\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maphasia_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtopic\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcollected\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    121\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    122\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m collected[:n]\n",
      "File \u001B[0;32m~/PycharmProjects/Barbara_things/afasia_llm_project/afasia_llm/generate.py:51\u001B[0m, in \u001B[0;36mgenerate_exercises_local\u001B[0;34m(severity, aphasia_type, topic, n)\u001B[0m\n\u001B[1;32m     49\u001B[0m valid \u001B[38;5;241m=\u001B[39m [c \u001B[38;5;28;01mfor\u001B[39;00m c \u001B[38;5;129;01min\u001B[39;00m cand \u001B[38;5;28;01mif\u001B[39;00m is_valid_exercise(c)]\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(valid) \u001B[38;5;241m<\u001B[39m n:\n\u001B[0;32m---> 51\u001B[0m     e \u001B[38;5;241m=\u001B[39m \u001B[43mrandom\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchoice\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m e \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m valid:\n\u001B[1;32m     53\u001B[0m         valid\u001B[38;5;241m.\u001B[39mappend(e)\n",
      "File \u001B[0;32m/opt/homebrew/Cellar/python@3.9/3.9.21/Frameworks/Python.framework/Versions/3.9/lib/python3.9/random.py:346\u001B[0m, in \u001B[0;36mRandom.choice\u001B[0;34m(self, seq)\u001B[0m\n\u001B[1;32m    344\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Choose a random element from a non-empty sequence.\"\"\"\u001B[39;00m\n\u001B[1;32m    345\u001B[0m \u001B[38;5;66;03m# raises IndexError if seq is empty\u001B[39;00m\n\u001B[0;32m--> 346\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m seq[\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_randbelow\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mseq\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m]\n",
      "File \u001B[0;32m/opt/homebrew/Cellar/python@3.9/3.9.21/Frameworks/Python.framework/Versions/3.9/lib/python3.9/random.py:245\u001B[0m, in \u001B[0;36mRandom._randbelow_with_getrandbits\u001B[0;34m(self, n)\u001B[0m\n\u001B[1;32m    243\u001B[0m k \u001B[38;5;241m=\u001B[39m n\u001B[38;5;241m.\u001B[39mbit_length()  \u001B[38;5;66;03m# don't use (n-1) here because n can be 1\u001B[39;00m\n\u001B[1;32m    244\u001B[0m r \u001B[38;5;241m=\u001B[39m getrandbits(k)  \u001B[38;5;66;03m# 0 <= r < 2**k\u001B[39;00m\n\u001B[0;32m--> 245\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[43mr\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m>\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m:\n\u001B[1;32m    246\u001B[0m     r \u001B[38;5;241m=\u001B[39m getrandbits(k)\n\u001B[1;32m    247\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m r\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "metrics = df[[\"llm_valid\", \"loc_valid\", \"llm_novel\", \"loc_novel\", \"t_llm\", \"t_loc\"]].describe().round(2).T\n",
    "metrics"
   ],
   "id": "601a591567a07535",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "sns.boxplot(data=df.melt(value_vars=[\"llm_valid\", \"loc_valid\"], var_name=\"mode\", value_name=\"valid\"), x=\"mode\",\n",
    "            y=\"valid\", ax=axes[0])\n",
    "axes[0].set_title(\"% válidos (5=max)\")\n",
    "\n",
    "sns.boxplot(data=df.melt(value_vars=[\"llm_novel\", \"loc_novel\"], var_name=\"mode\", value_name=\"novel\"), x=\"mode\",\n",
    "            y=\"novel\", ax=axes[1])\n",
    "axes[1].set_title(\"Novedad\")\n",
    "axes[1].set_ylabel(\"Ratio\")\n",
    "\n",
    "sns.boxplot(data=df.melt(value_vars=[\"t_llm\", \"t_loc\"], var_name=\"mode\", value_name=\"time\"), x=\"mode\", y=\"time\",\n",
    "            ax=axes[2])\n",
    "axes[2].set_title(\"Tiempo (s)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "b3fe201010950770",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "kpis = pd.DataFrame({\n",
    "    \"Metric\": [\n",
    "        \"Validez LLM (%)\",\n",
    "        \"Novedad LLM (%)\",\n",
    "        \"Tiempo LLM p50 (s)\",\n",
    "        \"Tiempo LLM p95 (s)\",\n",
    "        \"Fallback rate (%)\"\n",
    "    ],\n",
    "    \"Value\": [\n",
    "        df[\"llm_valid\"].mean() * 20,\n",
    "        df[\"llm_novel\"].mean() * 100,\n",
    "        df[\"t_llm\"].median(),\n",
    "        df[\"t_llm\"].quantile(.95),\n",
    "        100 - df[\"llm_valid\"].mean() * 20\n",
    "    ]\n",
    "}).round(2)\n",
    "\n",
    "kpis"
   ],
   "id": "619b6521ce41ea94",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "mdl_emb = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def extra_metrics(batch: list[str]) -> dict[str, float]:\n",
    "    toks = [w for ex in batch for w in ex.split()]\n",
    "    ttr = len(set(toks)) / len(toks) if toks else 0\n",
    "    embs = mdl_emb.encode(batch, convert_to_tensor=True)\n",
    "    sims = util.cos_sim(embs, embs).cpu().numpy()\n",
    "    upper = sims[np.triu_indices(len(batch), k=1)]\n",
    "    div = 1 - upper.mean() if len(upper) else 0\n",
    "    sb = np.mean([\n",
    "        sentence_bleu([e2.split()], e1.split())\n",
    "        for i, e1 in enumerate(batch) for j, e2 in enumerate(batch) if i != j\n",
    "    ])\n",
    "    return dict(\n",
    "        length_tok=len(toks) / len(batch),\n",
    "        type_token=ttr * 100,\n",
    "        embed_div=div * 100,\n",
    "        self_bleu=sb * 100\n",
    "    )\n",
    "\n",
    "llm_items = list(itertools.chain.from_iterable(\n",
    "    generate_exercises_llm(p[\"sev\"], p[\"type\"], \"daily activities\", n=5)\n",
    "    for p in patients[:60]\n",
    "))\n",
    "\n",
    "extra = extra_metrics(llm_items)\n",
    "\n",
    "kpis_extra = pd.DataFrame({\n",
    "    \"Metric\": [\"Tokens / ex\", \"Type–token (%)\", \"Embed diversity (%)\", \"Self-BLEU (%)\"],\n",
    "    \"Value\": [round(extra[\"length_tok\"], 2),\n",
    "              round(extra[\"type_token\"], 1),\n",
    "              round(extra[\"embed_div\"], 1),\n",
    "              round(extra[\"self_bleu\"], 1)]\n",
    "})\n",
    "\n",
    "kpis = pd.concat([kpis, kpis_extra], ignore_index=True)\n",
    "display(kpis.reset_index(drop=True))"
   ],
   "id": "9aae7e52822517aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "NAME_VALID = \"Validez LLM (%)\"\n",
    "NAME_NOVEL = \"Novedad LLM (%)\"\n",
    "NAME_LAT_P95 = \"Tiempo LLM p95 (s)\"\n",
    "\n",
    "pretty = (\n",
    "    df.groupby(\"type\")\n",
    "    .agg({\n",
    "        NAME_VALID: (\"llm_valid\", lambda x: x.mean() * 20),\n",
    "        NAME_NOVEL: (\"llm_novel\", lambda x: x.mean() * 100),\n",
    "        NAME_LAT_P95: (\"t_llm\", lambda x: x.quantile(.95))\n",
    "    })\n",
    "    .round(1)\n",
    "    .rename_axis(\"Tipo\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "display(pretty)\n",
    "\n",
    "# Validez y novedad por tipo\n",
    "pretty.set_index(\"Tipo\")[[NAME_VALID, NAME_NOVEL]].plot(\n",
    "    kind=\"bar\", figsize=(6, 4), color=[\"#2D7142\", \"#C9A42F\"]\n",
    ")\n",
    "plt.ylabel(\"%\")\n",
    "plt.title(\"Validez / Novedad por tipo de afasia\")\n",
    "plt.ylim(0, 100)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Por severidad\n",
    "sev_stats = (\n",
    "    df.groupby(\"sev\")\n",
    "    .agg({NAME_VALID: \"mean\", NAME_NOVEL: \"mean\"})\n",
    "    .mul([20, 100])\n",
    "    .round(1)\n",
    "    .rename_axis(\"Severidad\")\n",
    ")\n",
    "\n",
    "sev_stats[[NAME_VALID, NAME_NOVEL]].plot(\n",
    "    kind=\"bar\", figsize=(6, 4), color=[\"#4E95D9\", \"#C9A42F\"]\n",
    ")\n",
    "plt.ylabel(\"%\")\n",
    "plt.title(\"Validez / Novedad por severidad\")\n",
    "plt.ylim(0, 100)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "b534a7b28b0598a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "sns.countplot(data=df_patients, x=\"type\", ax=axes[0])\n",
    "axes[0].set_title(\"Distribución por tipo de afasia\")\n",
    "\n",
    "sns.countplot(data=df_patients, x=\"sev\", order=[\"Severe\", \"Moderate\", \"Mild\"], ax=axes[1])\n",
    "axes[1].set_title(\"Distribución por severidad\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Crosstab conjunto\n",
    "pd.crosstab(df_patients[\"type\"], df_patients[\"sev\"]).plot(\n",
    "    kind=\"bar\", stacked=True, colormap=\"Set2\", figsize=(8, 4)\n",
    ")\n",
    "plt.title(\"Distribución conjunta (tipo × severidad)\")\n",
    "plt.ylabel(\"Nº pacientes\")\n",
    "plt.xlabel(\"Tipo de afasia\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "20875442bc529d62",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "13825a5ffa9222e6",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (spaCy)",
   "language": "python",
   "name": "spacy39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
